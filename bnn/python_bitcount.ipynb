{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Binary Softmax Classifier in one line of pure Python\n",
    "\n",
    "A BNN just relies on XNOR and POPCNT.\n",
    "This can be accomplished in Python as\n",
    "\n",
    "```bin(a ^ b).count('0')```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data, reduce resolution to 14x14, and binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '5')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import MNIST dataset and show an image\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0,), (1.0,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "validset = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "\n",
    "def binarize_image(image):\n",
    "  # binarize\n",
    "  image = torch.where(image > 0., 1., -1.)\n",
    "  # 2x2 max pooling\n",
    "  image = image.view(1, 28, 28)\n",
    "  image = torch.nn.functional.max_pool2d(image, 2, stride=2)\n",
    "  image = image.view(14, 14)\n",
    "  return image\n",
    "\n",
    "# plot the first image in the dataset\n",
    "image, label = trainset[0]\n",
    "image = binarize_image(image)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert bitarrays to integers. (Both the images and the weights must be converted.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interger representation of the image: \n",
      "\t22454421217215396784785283249936507327682043917107200\n"
     ]
    }
   ],
   "source": [
    "def bits_to_int(bits):\n",
    "    \"\"\" Convert a Tensor of ±1 weights to an integer \"\"\"\n",
    "    return sum([2**i if w == 1 else 0 for i, w in enumerate(bits)])\n",
    "image_number = bits_to_int(image.view(-1))\n",
    "print('Interger representation of the image: ', image_number, sep='\\n\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer representation of the weights: \n",
      "\t69202147822387071132704518855746991949367362255233210354605\n",
      "\t18878814369946987095797706140359643633980551298119608171906\n",
      "\t78540396832536585483368402375151028044931349665181813605288\n",
      "\t59651287096264206496523126758990045730903949349863093764934\n",
      "\t37678846380222160407391793392907136717717661087841581533832\n",
      "\t3171297574277440634209123696293269987358799324618069912093\n",
      "\t94466091066229680046463532016975435255882059900073535301564\n",
      "\t25062623171492492486445059995270854716374161591472388719938\n",
      "\t65926414588134245937835258476719655445011905679206494796871\n",
      "\t50098809060764840098273587919356234368900679506047675839944\n"
     ]
    }
   ],
   "source": [
    "from bnn.softmax_regression import Net\n",
    "from bnn.binary_connect_utils import BCSampler\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('models/softmax.pt'))\n",
    "binary_weights = BCSampler.apply(model.fc1.weight)\n",
    "weight_numbers = list(bits_to_int(w) for w in binary_weights)\n",
    "print('Integer representation of the weights: ', *weight_numbers, sep='\\n\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The BNN\n",
    "\n",
    "We can implement XNOR + POPCNT as\n",
    "```\n",
    "bin(image ^ weight_number).count('0')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digits sorted by increasing likelihood:  [9, 7, 4, 6, 2, 0, 1, 5, 8, 3]\n"
     ]
    }
   ],
   "source": [
    "def similarity(image, weight_number):\n",
    "  return bin(image ^ weight_number).count('0')\n",
    "\n",
    "# example usage\n",
    "print('Digits sorted by increasing likelihood: ', \n",
    "  sorted(range(10), key = lambda d: similarity(image_number, weight_numbers[d]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:07<00:00, 1421.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy:  0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "correct = 0\n",
    "for i in tqdm(range(len(validset))):\n",
    "    image, label = validset[i]\n",
    "    image = binarize_image(image)\n",
    "    # image.view(-1)\n",
    "    image = bits_to_int(image.view(-1))\n",
    "    correct += (label == max(range(10), key = lambda d: similarity(image, weight_numbers[d])))\n",
    "\n",
    "print('Final accuracy: ', correct / len(validset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We can classify an image in 2ms with 70% accuracy. This includes the time required to preprocess (downsample and binarize) the image!\n",
    "\n",
    "We can do this in pure Python without any external dependencies.\n",
    "\n",
    "This strategy could make it easy to add a little machine learning to a leighweight library which shouldn't depend on scientific libraries like numpy. All you need to do is include your weight numbers as a list directly in the source code and use the XOR and COUNT operators available in pure Python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnn-GRwNpjPu-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
